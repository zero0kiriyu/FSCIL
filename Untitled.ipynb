{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-slovak",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "automatic-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "neither-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (sentence for sentence in content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ranking-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in content:\n",
    "    b = (sentence,)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sweet-dominican",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "micro-warner",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/zhongshengtao/.cache/torch/hub/pytorch_vision_v0.8.1\n"
     ]
    }
   ],
   "source": [
    "#model = torch.hub.load('pytorch/vision:v0.8.1', 'vgg11', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mighty-algebra",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = CIFAR100(root='cifar100',train=True)\n",
    "test = CIFAR100(root='cifar100',train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "recent-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = 9\n",
    "index = [np.zeros((session,500),dtype=int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stable-canon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "stuffed-flooring",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 500 is out of bounds for axis 0 with size 500",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4d3f8e5b83ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cifar100_index/session_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 500 is out of bounds for axis 0 with size 500"
     ]
    }
   ],
   "source": [
    "for i in range(session):\n",
    "    count = 0\n",
    "    for line in open(\"cifar100_index/session_\"+str(i+1)+\".txt\"):\n",
    "        index[i][count] = int(line)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "normal-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = [train[i][1] for i in index_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-scholar",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NC_CIFAR100(dataset._DownloadedDataset):\n",
    "    \"\"\"CIFAR100 image classification dataset from https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "    Each sample is an image (in 3D NDArray) with shape (32, 32, 1).\n",
    "    Parameters\n",
    "    ----------\n",
    "    root : str, default $MXNET_HOME/datasets/cifar100\n",
    "        Path to temp folder for storing data.\n",
    "    fine_label : bool, default False\n",
    "        Whether to load the fine-grained (100 classes) or coarse-grained (20 super-classes) labels.\n",
    "    train : bool, default True\n",
    "        Whether to load the training or testing set.\n",
    "    transform : function, default None\n",
    "        A user defined callback that transforms each sample. For example:\n",
    "    ::\n",
    "        transform=lambda data, label: (data.astype(np.float32)/255, label)\n",
    "    \"\"\"\n",
    "    def __init__(self, logger, root=os.path.join(base.data_dir(), 'datasets', 'cifar100'),\n",
    "                 fine_label=False, train=True, transform=None, c_way=5, k_shot=5, fix_class=None, base_class=0):\n",
    "        self.name = 'NC_CIFAR100'\n",
    "        self._train = train\n",
    "        self._archive_file = ('cifar-100-binary.tar.gz', 'a0bb982c76b83111308126cc779a992fa506b90b')\n",
    "        self._train_data = [('train.bin', 'e207cd2e05b73b1393c74c7f5e7bea451d63e08e')]\n",
    "        self._test_data = [('test.bin', '8fb6623e830365ff53cf14adec797474f5478006')]\n",
    "        self._fine_label = fine_label\n",
    "        self._namespace = 'cifar100'\n",
    "        self._c_way = c_way\n",
    "        self._k_shot = k_shot\n",
    "        self._fix_class = fix_class\n",
    "        self._base_class = base_class\n",
    "        self._logger = logger\n",
    "        super(NC_CIFAR100, self).__init__(root, transform) # pylint: disable=bad-super-call\n",
    "\n",
    "    def _read_batch(self, filename):\n",
    "        with open(filename, 'rb') as fin:\n",
    "            data = np.frombuffer(fin.read(), dtype=np.uint8).reshape(-1, 3072+2)\n",
    "        return data[:, 2:].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1), \\\n",
    "               data[:, 0+self._fine_label].astype(np.int32)\n",
    "\n",
    "    def _get_data(self):\n",
    "\n",
    "        if any(not os.path.exists(path) or not check_sha1(path, sha1)\n",
    "               for path, sha1 in ((os.path.join(self._root, name), sha1)\n",
    "                                  for name, sha1 in self._train_data + self._test_data)):\n",
    "            namespace = 'gluon/dataset/'+self._namespace\n",
    "            filename = download(_get_repo_file_url(namespace, self._archive_file[0]),\n",
    "                                path=self._root,\n",
    "                                sha1_hash=self._archive_file[1])\n",
    "\n",
    "            with tarfile.open(filename) as tar:\n",
    "                tar.extractall(self._root)\n",
    "\n",
    "        if self._train:\n",
    "            data_files = self._train_data\n",
    "        else:\n",
    "            data_files = self._test_data\n",
    "        data, label = zip(*(self._read_batch(os.path.join(self._root, name))\n",
    "                            for name, _ in data_files))\n",
    "\n",
    "        data = np.concatenate(data)\n",
    "        label = np.concatenate(label)\n",
    "        if not self._fix_class:\n",
    "            np.random.seed(0)\n",
    "            classes = np.random.choice(np.max(label)+1,size=self._c_way,replace=False)\n",
    "            self._fix_class = list(classes)\n",
    "        if self._logger:\n",
    "            self._logger.info('select CIFAR100 classes : {} , fine label = {}, train = {}'.\n",
    "                  format(self._fix_class, self._fine_label, self._train))\n",
    "\n",
    "        if self._train:\n",
    "            select_index = list()\n",
    "            new_label = list()\n",
    "            for i,l in enumerate(self._fix_class):\n",
    "                ind = list(np.where(l==label)[0])\n",
    "                np.random.seed(1)\n",
    "                random_ind = np.random.choice(ind,self._k_shot,replace=False)\n",
    "                select_index.extend(random_ind)\n",
    "                new_label.extend([i+self._base_class]*len(random_ind))\n",
    "            data = data[select_index]\n",
    "            label = np.array(new_label)\n",
    "        else:\n",
    "            select_index = list()\n",
    "            new_label = list()\n",
    "            for i,l in enumerate(self._fix_class):\n",
    "                ind = list(np.where(l==label)[0])\n",
    "                select_index.extend(ind)\n",
    "                new_label.extend([i+self._base_class]*len(ind))\n",
    "            data = data[select_index]\n",
    "            label = np.array(new_label)\n",
    "\n",
    "        self._data = nd.array(data, dtype=data.dtype)\n",
    "        self._label = label\n",
    "        if self._logger:\n",
    "            self._logger.info('the number of cifar100 new class samples : %d'%(label.shape[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:science] *",
   "language": "python",
   "name": "conda-env-science-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
